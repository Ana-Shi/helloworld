{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归：  \n",
    "\n",
    "解决回归问题  \n",
    "\n",
    "思想简单容易实现  \n",
    "\n",
    "许多强大的非线性模型的基础 ： 多项式回归，逻辑回归，SVM都可以理解为线性回归的一种拓展\n",
    "\n",
    "结果具有很好的解释性  \n",
    "\n",
    "蕴含机器学习中许多重要思想\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设特征与目标值之间的关系是线性的，寻找一条直线可以最大程度的拟合特征和目标值之间的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单线性回归：特征只有一个的回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> y = a*x +b 假设找到最佳拟合直线方程  \n",
    "\n",
    "    对于每一个样本点xi  \n",
    "\n",
    "    y^i = axi +b, 预测值  \n",
    "\n",
    "     我们希望找到a和b的值使yi和y^i的差距尽可能小：  \n",
    "\n",
    "     argmin sum((yi-y^i)^2)  i=1,...n   \n",
    "\n",
    "\n",
    "     argmin sum((yi-a*xi-b)^2)  i=1,...n \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 机器学习套路  \n",
    "\n",
    "建模过程： 找到一个模型最大限度的拟合数据\n",
    "找到损失函数，度量模型没有拟合模型的部分  \n",
    "通过分析问题确定问题的损失函数；  \n",
    "通过最优化损失函数或者效用函数，获得机器学习的模型。  \n",
    "几乎所有的参数学习都是这个套路，即机器学习是在学习参数，找到参数可以最优化损失函数或者效用函数  \n",
    "区别在于模型不同，目标函数不同，优化的方式也不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
