{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实现Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5])\n",
    "y = np.array([1,3,2,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xa151cf8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SIMPLE_rEGRESSION]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img style = 'float: right' src='./simple_regression.png',width='40%',height=200>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<img style = 'float: right' src='./simple_regression.png',width='40%',height=200>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_mean = np.mean(x)\n",
    "y_mean = np.mean(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = 0.0\n",
    "d=0.0\n",
    "for x_i,y_i in zip(x,y):\n",
    "    num += (x_i-x_mean)*(y_i-y_mean)\n",
    "    d += (x_i-x_mean)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = num/d\n",
    "b = y_mean - a*x_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90000000000000002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_predict = a*x +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5833048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.plot(x,Y_predict,color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from playML import SimpleLinearRegression1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.7])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_predict = 6\n",
    "reg1 = SimpleLinearRegression1()\n",
    "reg1.fit(x,y)\n",
    "reg1.predict(np.array([x_predict]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归算法的评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "找到a,b是目标函数在训练集上尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "衡量标准MSE: 1/M * sum((y_test - y_predict)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE: sqrt(1/M * sum((y_test - y_predict)^2))  = sqrt(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均绝对误差MAE : 1/M * sum(abs(y_test-y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = boston.data[:,4:6]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = boston.target\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xc09def0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(x[:,1],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = x[y<50,0]\n",
    "b = x[y<50,1]\n",
    "y = y[y<50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([a,b]).T\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xc0bb400>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.scatter(x1[:,1],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x1,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.871 ,  5.404 ],\n",
       "       [ 0.74  ,  6.459 ],\n",
       "       [ 0.464 ,  5.856 ],\n",
       "       [ 0.469 ,  7.185 ],\n",
       "       [ 0.389 ,  6.453 ],\n",
       "       [ 0.532 ,  5.762 ],\n",
       "       [ 0.713 ,  6.297 ],\n",
       "       [ 0.655 ,  5.952 ],\n",
       "       [ 0.507 ,  6.164 ],\n",
       "       [ 0.74  ,  6.341 ],\n",
       "       [ 0.538 ,  6.575 ],\n",
       "       [ 0.584 ,  5.565 ],\n",
       "       [ 0.488 ,  6.144 ],\n",
       "       [ 0.74  ,  5.627 ],\n",
       "       [ 0.544 ,  6.122 ],\n",
       "       [ 0.605 ,  5.877 ],\n",
       "       [ 0.489 ,  5.891 ],\n",
       "       [ 0.52  ,  6.137 ],\n",
       "       [ 0.871 ,  5.403 ],\n",
       "       [ 0.538 ,  5.456 ],\n",
       "       [ 0.647 ,  7.206 ],\n",
       "       [ 0.713 ,  5.976 ],\n",
       "       [ 0.624 ,  6.431 ],\n",
       "       [ 0.431 ,  6.438 ],\n",
       "       [ 0.7   ,  5.536 ],\n",
       "       [ 0.507 ,  6.726 ],\n",
       "       [ 0.426 ,  6.302 ],\n",
       "       [ 0.449 ,  6.015 ],\n",
       "       [ 0.448 ,  6.169 ],\n",
       "       [ 0.437 ,  6.782 ],\n",
       "       [ 0.515 ,  6.316 ],\n",
       "       [ 0.538 ,  6.495 ],\n",
       "       [ 0.4   ,  7.088 ],\n",
       "       [ 0.52  ,  6.229 ],\n",
       "       [ 0.51  ,  6.86  ],\n",
       "       [ 0.447 ,  6.758 ],\n",
       "       [ 0.532 ,  6.75  ],\n",
       "       [ 0.77  ,  6.251 ],\n",
       "       [ 0.52  ,  5.836 ],\n",
       "       [ 0.437 ,  6.739 ],\n",
       "       [ 0.584 ,  6.162 ],\n",
       "       [ 0.447 ,  6.482 ],\n",
       "       [ 0.52  ,  6.405 ],\n",
       "       [ 0.614 ,  5.648 ],\n",
       "       [ 0.659 ,  5.608 ],\n",
       "       [ 0.4429,  6.968 ],\n",
       "       [ 0.77  ,  5.803 ],\n",
       "       [ 0.679 ,  6.434 ],\n",
       "       [ 0.4429,  7.82  ],\n",
       "       [ 0.507 ,  6.879 ],\n",
       "       [ 0.693 ,  5.453 ],\n",
       "       [ 0.493 ,  6.312 ],\n",
       "       [ 0.609 ,  5.983 ],\n",
       "       [ 0.597 ,  6.657 ],\n",
       "       [ 0.718 ,  6.824 ],\n",
       "       [ 0.46  ,  6.333 ],\n",
       "       [ 0.544 ,  5.972 ],\n",
       "       [ 0.52  ,  6.781 ],\n",
       "       [ 0.504 ,  6.552 ],\n",
       "       [ 0.51  ,  5.859 ],\n",
       "       [ 0.426 ,  6.727 ],\n",
       "       [ 0.458 ,  6.998 ],\n",
       "       [ 0.41  ,  6.383 ],\n",
       "       [ 0.74  ,  6.629 ],\n",
       "       [ 0.524 ,  6.172 ],\n",
       "       [ 0.445 ,  6.163 ],\n",
       "       [ 0.404 ,  7.274 ],\n",
       "       [ 0.544 ,  5.705 ],\n",
       "       [ 0.538 ,  6.096 ],\n",
       "       [ 0.547 ,  5.913 ],\n",
       "       [ 0.413 ,  5.663 ],\n",
       "       [ 0.403 ,  7.135 ],\n",
       "       [ 0.439 ,  6.115 ],\n",
       "       [ 0.532 ,  6.229 ],\n",
       "       [ 0.74  ,  6.461 ],\n",
       "       [ 0.433 ,  6.495 ],\n",
       "       [ 0.538 ,  5.949 ],\n",
       "       [ 0.671 ,  6.649 ],\n",
       "       [ 0.431 ,  6.108 ],\n",
       "       [ 0.428 ,  6.606 ],\n",
       "       [ 0.605 ,  5.875 ],\n",
       "       [ 0.488 ,  6.153 ],\n",
       "       [ 0.538 ,  5.935 ],\n",
       "       [ 0.4161,  7.104 ],\n",
       "       [ 0.7   ,  5.036 ],\n",
       "       [ 0.431 ,  6.226 ],\n",
       "       [ 0.435 ,  6.635 ],\n",
       "       [ 0.453 ,  5.741 ],\n",
       "       [ 0.624 ,  5.757 ],\n",
       "       [ 0.538 ,  5.834 ],\n",
       "       [ 0.41  ,  6.728 ],\n",
       "       [ 0.597 ,  5.155 ],\n",
       "       [ 0.871 ,  5.709 ],\n",
       "       [ 0.426 ,  6.619 ],\n",
       "       [ 0.679 ,  5.896 ],\n",
       "       [ 0.437 ,  5.79  ],\n",
       "       [ 0.679 ,  6.202 ],\n",
       "       [ 0.398 ,  5.787 ],\n",
       "       [ 0.631 ,  3.863 ],\n",
       "       [ 0.464 ,  7.691 ],\n",
       "       [ 0.7   ,  5.52  ],\n",
       "       [ 0.7   ,  5.713 ],\n",
       "       [ 0.488 ,  7.765 ],\n",
       "       [ 0.583 ,  5.905 ],\n",
       "       [ 0.415 ,  7.61  ],\n",
       "       [ 0.445 ,  6.625 ],\n",
       "       [ 0.447 ,  7.267 ],\n",
       "       [ 0.544 ,  4.973 ],\n",
       "       [ 0.74  ,  6.152 ],\n",
       "       [ 0.624 ,  6.326 ],\n",
       "       [ 0.584 ,  5.837 ],\n",
       "       [ 0.464 ,  6.211 ],\n",
       "       [ 0.693 ,  5.852 ],\n",
       "       [ 0.713 ,  6.436 ],\n",
       "       [ 0.605 ,  5.854 ],\n",
       "       [ 0.581 ,  5.856 ],\n",
       "       [ 0.4   ,  6.345 ],\n",
       "       [ 0.448 ,  5.786 ],\n",
       "       [ 0.411 ,  6.816 ],\n",
       "       [ 0.507 ,  6.086 ],\n",
       "       [ 0.547 ,  6.254 ],\n",
       "       [ 0.693 ,  6.471 ],\n",
       "       [ 0.431 ,  6.718 ],\n",
       "       [ 0.515 ,  6.31  ],\n",
       "       [ 0.871 ,  5.012 ],\n",
       "       [ 0.668 ,  4.906 ],\n",
       "       [ 0.713 ,  6.655 ],\n",
       "       [ 0.77  ,  6.398 ],\n",
       "       [ 0.437 ,  6.678 ],\n",
       "       [ 0.597 ,  6.852 ],\n",
       "       [ 0.585 ,  6.027 ],\n",
       "       [ 0.584 ,  6.425 ],\n",
       "       [ 0.693 ,  6.404 ],\n",
       "       [ 0.693 ,  5.349 ],\n",
       "       [ 0.647 ,  5.56  ],\n",
       "       [ 0.538 ,  6.674 ],\n",
       "       [ 0.449 ,  6.389 ],\n",
       "       [ 0.507 ,  6.951 ],\n",
       "       [ 0.55  ,  6.373 ],\n",
       "       [ 0.55  ,  5.888 ],\n",
       "       [ 0.609 ,  5.454 ],\n",
       "       [ 0.453 ,  6.762 ],\n",
       "       [ 0.489 ,  6.375 ],\n",
       "       [ 0.713 ,  6.525 ],\n",
       "       [ 0.51  ,  6.546 ],\n",
       "       [ 0.671 ,  6.794 ],\n",
       "       [ 0.547 ,  6.176 ],\n",
       "       [ 0.437 ,  6.127 ],\n",
       "       [ 0.431 ,  5.605 ],\n",
       "       [ 0.538 ,  5.599 ],\n",
       "       [ 0.55  ,  5.951 ],\n",
       "       [ 0.464 ,  6.442 ],\n",
       "       [ 0.693 ,  5.531 ],\n",
       "       [ 0.428 ,  7.024 ],\n",
       "       [ 0.437 ,  5.874 ],\n",
       "       [ 0.609 ,  5.414 ],\n",
       "       [ 0.442 ,  5.898 ],\n",
       "       [ 0.448 ,  6.03  ],\n",
       "       [ 0.437 ,  6.549 ],\n",
       "       [ 0.51  ,  5.572 ],\n",
       "       [ 0.448 ,  5.399 ],\n",
       "       [ 0.871 ,  6.51  ],\n",
       "       [ 0.624 ,  5.822 ],\n",
       "       [ 0.484 ,  6.696 ],\n",
       "       [ 0.448 ,  6.069 ],\n",
       "       [ 0.605 ,  5.88  ],\n",
       "       [ 0.488 ,  5.604 ],\n",
       "       [ 0.871 ,  4.903 ],\n",
       "       [ 0.693 ,  6.193 ],\n",
       "       [ 0.573 ,  6.976 ],\n",
       "       [ 0.472 ,  6.616 ],\n",
       "       [ 0.489 ,  5.807 ],\n",
       "       [ 0.713 ,  7.393 ],\n",
       "       [ 0.472 ,  6.849 ],\n",
       "       [ 0.605 ,  6.402 ],\n",
       "       [ 0.671 ,  7.313 ],\n",
       "       [ 0.718 ,  8.78  ],\n",
       "       [ 0.77  ,  6.212 ],\n",
       "       [ 0.429 ,  6.49  ],\n",
       "       [ 0.437 ,  6.273 ],\n",
       "       [ 0.584 ,  5.427 ],\n",
       "       [ 0.575 ,  7.47  ],\n",
       "       [ 0.493 ,  6.431 ],\n",
       "       [ 0.453 ,  6.456 ],\n",
       "       [ 0.605 ,  6.943 ],\n",
       "       [ 0.7   ,  5.    ],\n",
       "       [ 0.428 ,  6.897 ],\n",
       "       [ 0.605 ,  6.319 ],\n",
       "       [ 0.437 ,  6.951 ],\n",
       "       [ 0.871 ,  5.468 ],\n",
       "       [ 0.449 ,  6.121 ],\n",
       "       [ 0.679 ,  6.782 ],\n",
       "       [ 0.671 ,  6.545 ],\n",
       "       [ 0.585 ,  5.569 ],\n",
       "       [ 0.439 ,  6.511 ],\n",
       "       [ 0.431 ,  8.259 ],\n",
       "       [ 0.431 ,  6.433 ],\n",
       "       [ 0.437 ,  7.178 ],\n",
       "       [ 0.489 ,  5.344 ],\n",
       "       [ 0.77  ,  6.127 ],\n",
       "       [ 0.538 ,  5.713 ],\n",
       "       [ 0.52  ,  6.195 ],\n",
       "       [ 0.7   ,  4.652 ],\n",
       "       [ 0.713 ,  6.417 ],\n",
       "       [ 0.605 ,  6.101 ],\n",
       "       [ 0.524 ,  6.004 ],\n",
       "       [ 0.458 ,  6.43  ],\n",
       "       [ 0.426 ,  6.167 ],\n",
       "       [ 0.488 ,  6.563 ],\n",
       "       [ 0.51  ,  6.416 ],\n",
       "       [ 0.429 ,  6.516 ],\n",
       "       [ 0.411 ,  6.63  ],\n",
       "       [ 0.413 ,  6.245 ],\n",
       "       [ 0.518 ,  6.54  ],\n",
       "       [ 0.499 ,  5.933 ],\n",
       "       [ 0.693 ,  5.747 ],\n",
       "       [ 0.453 ,  5.927 ],\n",
       "       [ 0.655 ,  5.759 ],\n",
       "       [ 0.504 ,  5.981 ],\n",
       "       [ 0.493 ,  6.041 ],\n",
       "       [ 0.624 ,  6.151 ],\n",
       "       [ 0.647 ,  7.52  ],\n",
       "       [ 0.52  ,  6.727 ],\n",
       "       [ 0.428 ,  6.393 ],\n",
       "       [ 0.624 ,  5.857 ],\n",
       "       [ 0.507 ,  6.618 ],\n",
       "       [ 0.584 ,  6.833 ],\n",
       "       [ 0.453 ,  6.145 ],\n",
       "       [ 0.524 ,  5.631 ],\n",
       "       [ 0.51  ,  6.315 ],\n",
       "       [ 0.74  ,  6.251 ],\n",
       "       [ 0.584 ,  6.003 ],\n",
       "       [ 0.404 ,  7.107 ],\n",
       "       [ 0.499 ,  5.966 ],\n",
       "       [ 0.624 ,  6.458 ],\n",
       "       [ 0.413 ,  6.065 ],\n",
       "       [ 0.392 ,  5.876 ],\n",
       "       [ 0.507 ,  8.247 ],\n",
       "       [ 0.583 ,  5.871 ],\n",
       "       [ 0.74  ,  5.935 ],\n",
       "       [ 0.573 ,  6.593 ],\n",
       "       [ 0.713 ,  6.728 ],\n",
       "       [ 0.484 ,  6.874 ],\n",
       "       [ 0.671 ,  6.223 ],\n",
       "       [ 0.489 ,  5.783 ],\n",
       "       [ 0.409 ,  5.878 ],\n",
       "       [ 0.538 ,  5.813 ],\n",
       "       [ 0.464 ,  6.538 ],\n",
       "       [ 0.544 ,  6.266 ],\n",
       "       [ 0.624 ,  6.372 ],\n",
       "       [ 0.392 ,  6.108 ],\n",
       "       [ 0.659 ,  4.138 ],\n",
       "       [ 0.77  ,  6.112 ],\n",
       "       [ 0.713 ,  6.513 ],\n",
       "       [ 0.437 ,  6.14  ],\n",
       "       [ 0.524 ,  5.889 ],\n",
       "       [ 0.4379,  5.706 ],\n",
       "       [ 0.385 ,  6.23  ],\n",
       "       [ 0.597 ,  5.757 ],\n",
       "       [ 0.544 ,  6.567 ],\n",
       "       [ 0.614 ,  6.484 ],\n",
       "       [ 0.547 ,  6.715 ],\n",
       "       [ 0.489 ,  6.182 ],\n",
       "       [ 0.544 ,  6.113 ],\n",
       "       [ 0.51  ,  6.02  ],\n",
       "       [ 0.493 ,  5.708 ],\n",
       "       [ 0.415 ,  6.162 ],\n",
       "       [ 0.499 ,  5.841 ],\n",
       "       [ 0.538 ,  5.57  ],\n",
       "       [ 0.437 ,  6.232 ],\n",
       "       [ 0.447 ,  6.826 ],\n",
       "       [ 0.547 ,  6.021 ],\n",
       "       [ 0.437 ,  6.009 ],\n",
       "       [ 0.489 ,  6.417 ],\n",
       "       [ 0.504 ,  8.04  ],\n",
       "       [ 0.713 ,  6.185 ],\n",
       "       [ 0.871 ,  5.628 ],\n",
       "       [ 0.493 ,  6.376 ],\n",
       "       [ 0.585 ,  5.39  ],\n",
       "       [ 0.405 ,  6.315 ],\n",
       "       [ 0.493 ,  6.415 ],\n",
       "       [ 0.573 ,  6.12  ],\n",
       "       [ 0.52  ,  6.127 ],\n",
       "       [ 0.515 ,  6.059 ],\n",
       "       [ 0.585 ,  5.707 ],\n",
       "       [ 0.55  ,  6.642 ],\n",
       "       [ 0.713 ,  6.317 ],\n",
       "       [ 0.41  ,  5.888 ],\n",
       "       [ 0.7   ,  6.051 ],\n",
       "       [ 0.431 ,  6.957 ],\n",
       "       [ 0.515 ,  5.895 ],\n",
       "       [ 0.489 ,  5.412 ],\n",
       "       [ 0.581 ,  6.004 ],\n",
       "       [ 0.581 ,  5.961 ],\n",
       "       [ 0.515 ,  5.968 ],\n",
       "       [ 0.489 ,  7.079 ],\n",
       "       [ 0.524 ,  6.012 ],\n",
       "       [ 0.693 ,  4.519 ],\n",
       "       [ 0.437 ,  6.556 ],\n",
       "       [ 0.718 ,  6.411 ],\n",
       "       [ 0.713 ,  6.701 ],\n",
       "       [ 0.614 ,  6.103 ],\n",
       "       [ 0.538 ,  5.924 ],\n",
       "       [ 0.489 ,  6.405 ],\n",
       "       [ 0.538 ,  5.813 ],\n",
       "       [ 0.46  ,  5.868 ],\n",
       "       [ 0.647 ,  8.398 ],\n",
       "       [ 0.52  ,  6.474 ],\n",
       "       [ 0.624 ,  6.174 ],\n",
       "       [ 0.624 ,  5.019 ],\n",
       "       [ 0.609 ,  5.983 ],\n",
       "       [ 0.74  ,  6.219 ],\n",
       "       [ 0.413 ,  6.417 ],\n",
       "       [ 0.544 ,  5.914 ],\n",
       "       [ 0.581 ,  5.87  ],\n",
       "       [ 0.7   ,  5.277 ],\n",
       "       [ 0.439 ,  5.998 ],\n",
       "       [ 0.544 ,  6.382 ],\n",
       "       [ 0.4379,  6.031 ],\n",
       "       [ 0.403 ,  6.975 ],\n",
       "       [ 0.489 ,  6.064 ],\n",
       "       [ 0.453 ,  5.966 ],\n",
       "       [ 0.472 ,  7.236 ],\n",
       "       [ 0.573 ,  6.794 ],\n",
       "       [ 0.411 ,  6.861 ],\n",
       "       [ 0.871 ,  6.122 ],\n",
       "       [ 0.647 ,  7.014 ],\n",
       "       [ 0.447 ,  6.854 ],\n",
       "       [ 0.7   ,  4.368 ],\n",
       "       [ 0.504 ,  7.686 ],\n",
       "       [ 0.581 ,  5.613 ],\n",
       "       [ 0.573 ,  6.03  ],\n",
       "       [ 0.585 ,  5.926 ],\n",
       "       [ 0.547 ,  5.731 ],\n",
       "       [ 0.445 ,  7.416 ],\n",
       "       [ 0.398 ,  6.29  ],\n",
       "       [ 0.713 ,  5.936 ],\n",
       "       [ 0.405 ,  6.209 ],\n",
       "       [ 0.718 ,  4.963 ],\n",
       "       [ 0.871 ,  6.13  ],\n",
       "       [ 0.58  ,  5.713 ],\n",
       "       [ 0.77  ,  5.362 ],\n",
       "       [ 0.671 ,  6.38  ],\n",
       "       [ 0.458 ,  7.147 ],\n",
       "       [ 0.58  ,  6.167 ],\n",
       "       [ 0.693 ,  5.987 ],\n",
       "       [ 0.404 ,  7.287 ],\n",
       "       [ 0.411 ,  7.148 ],\n",
       "       [ 0.544 ,  6.023 ],\n",
       "       [ 0.52  ,  5.851 ],\n",
       "       [ 0.614 ,  6.185 ],\n",
       "       [ 0.718 ,  6.006 ],\n",
       "       [ 0.515 ,  5.869 ],\n",
       "       [ 0.431 ,  6.487 ],\n",
       "       [ 0.401 ,  6.8   ],\n",
       "       [ 0.624 ,  5.693 ],\n",
       "       [ 0.409 ,  5.885 ],\n",
       "       [ 0.538 ,  6.047 ],\n",
       "       [ 0.429 ,  6.939 ],\n",
       "       [ 0.679 ,  6.193 ],\n",
       "       [ 0.583 ,  6.114 ],\n",
       "       [ 0.679 ,  6.38  ],\n",
       "       [ 0.499 ,  5.85  ],\n",
       "       [ 0.4429,  6.812 ],\n",
       "       [ 0.583 ,  6.312 ],\n",
       "       [ 0.538 ,  5.727 ],\n",
       "       [ 0.489 ,  7.007 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.585 ,  5.67  ],\n",
       "       [ 0.74  ,  5.818 ],\n",
       "       [ 0.614 ,  6.229 ],\n",
       "       [ 0.428 ,  6.358 ],\n",
       "       [ 0.693 ,  5.887 ],\n",
       "       [ 0.713 ,  6.376 ],\n",
       "       [ 0.668 ,  4.138 ],\n",
       "       [ 0.718 ,  3.561 ],\n",
       "       [ 0.4   ,  6.871 ],\n",
       "       [ 0.4429,  7.645 ],\n",
       "       [ 0.428 ,  6.595 ],\n",
       "       [ 0.77  ,  6.395 ],\n",
       "       [ 0.428 ,  6.095 ],\n",
       "       [ 0.448 ,  5.682 ],\n",
       "       [ 0.597 ,  4.628 ],\n",
       "       [ 0.504 ,  8.266 ],\n",
       "       [ 0.464 ,  5.92  ],\n",
       "       [ 0.624 ,  5.637 ],\n",
       "       [ 0.445 ,  8.069 ],\n",
       "       [ 0.538 ,  5.701 ],\n",
       "       [ 0.547 ,  5.928 ],\n",
       "       [ 0.464 ,  6.249 ],\n",
       "       [ 0.584 ,  6.348 ],\n",
       "       [ 0.74  ,  5.854 ],\n",
       "       [ 0.472 ,  7.42  ],\n",
       "       [ 0.544 ,  6.635 ],\n",
       "       [ 0.538 ,  5.99  ],\n",
       "       [ 0.433 ,  6.59  ],\n",
       "       [ 0.437 ,  7.185 ],\n",
       "       [ 0.871 ,  4.926 ],\n",
       "       [ 0.671 ,  6.968 ],\n",
       "       [ 0.442 ,  6.014 ],\n",
       "       [ 0.413 ,  5.936 ],\n",
       "       [ 0.871 ,  6.129 ],\n",
       "       [ 0.693 ,  6.405 ],\n",
       "       [ 0.448 ,  6.211 ],\n",
       "       [ 0.547 ,  5.872 ],\n",
       "       [ 0.532 ,  7.061 ],\n",
       "       [ 0.647 ,  7.327 ],\n",
       "       [ 0.4161,  7.853 ],\n",
       "       [ 0.449 ,  6.63  ],\n",
       "       [ 0.679 ,  5.304 ],\n",
       "       [ 0.585 ,  5.794 ],\n",
       "       [ 0.433 ,  6.982 ],\n",
       "       [ 0.74  ,  6.485 ],\n",
       "       [ 0.693 ,  5.683 ],\n",
       "       [ 0.538 ,  5.95  ],\n",
       "       [ 0.428 ,  6.481 ],\n",
       "       [ 0.532 ,  6.242 ],\n",
       "       [ 0.493 ,  6.426 ],\n",
       "       [ 0.524 ,  6.009 ],\n",
       "       [ 0.401 ,  6.604 ],\n",
       "       [ 0.507 ,  6.631 ],\n",
       "       [ 0.871 ,  5.186 ],\n",
       "       [ 0.655 ,  6.209 ],\n",
       "       [ 0.4   ,  7.041 ],\n",
       "       [ 0.624 ,  6.454 ],\n",
       "       [ 0.46  ,  6.144 ],\n",
       "       [ 0.74  ,  6.406 ],\n",
       "       [ 0.647 ,  7.333 ],\n",
       "       [ 0.437 ,  6.286 ],\n",
       "       [ 0.605 ,  6.25  ],\n",
       "       [ 0.624 ,  5.942 ],\n",
       "       [ 0.507 ,  8.337 ],\n",
       "       [ 0.58  ,  6.437 ],\n",
       "       [ 0.524 ,  6.377 ],\n",
       "       [ 0.413 ,  5.961 ],\n",
       "       [ 0.713 ,  6.208 ],\n",
       "       [ 0.713 ,  6.301 ],\n",
       "       [ 0.7   ,  5.39  ],\n",
       "       [ 0.445 ,  7.82  ],\n",
       "       [ 0.58  ,  5.926 ],\n",
       "       [ 0.647 ,  7.203 ],\n",
       "       [ 0.581 ,  5.986 ],\n",
       "       [ 0.448 ,  6.77  ],\n",
       "       [ 0.605 ,  6.066 ],\n",
       "       [ 0.581 ,  5.879 ],\n",
       "       [ 0.504 ,  7.163 ],\n",
       "       [ 0.507 ,  7.358 ],\n",
       "       [ 0.538 ,  5.965 ],\n",
       "       [ 0.538 ,  6.096 ],\n",
       "       [ 0.544 ,  5.782 ],\n",
       "       [ 0.504 ,  7.412 ],\n",
       "       [ 0.871 ,  5.597 ],\n",
       "       [ 0.597 ,  5.617 ],\n",
       "       [ 0.489 ,  5.404 ],\n",
       "       [ 0.614 ,  5.304 ],\n",
       "       [ 0.624 ,  6.335 ],\n",
       "       [ 0.488 ,  7.155 ],\n",
       "       [ 0.538 ,  6.142 ],\n",
       "       [ 0.538 ,  6.072 ],\n",
       "       [ 0.442 ,  7.241 ],\n",
       "       [ 0.713 ,  6.749 ],\n",
       "       [ 0.515 ,  6.037 ],\n",
       "       [ 0.679 ,  5.957 ],\n",
       "       [ 0.411 ,  5.884 ],\n",
       "       [ 0.411 ,  6.579 ],\n",
       "       [ 0.439 ,  5.963 ],\n",
       "       [ 0.489 ,  5.96  ],\n",
       "       [ 0.515 ,  5.985 ],\n",
       "       [ 0.585 ,  6.019 ],\n",
       "       [ 0.464 ,  6.24  ],\n",
       "       [ 0.647 ,  6.842 ],\n",
       "       [ 0.448 ,  5.602 ],\n",
       "       [ 0.431 ,  5.593 ],\n",
       "       [ 0.409 ,  5.594 ],\n",
       "       [ 0.7   ,  4.88  ],\n",
       "       [ 0.614 ,  6.98  ],\n",
       "       [ 0.403 ,  7.249 ],\n",
       "       [ 0.493 ,  6.083 ],\n",
       "       [ 0.547 ,  6.092 ],\n",
       "       [ 0.871 ,  5.272 ],\n",
       "       [ 0.609 ,  5.093 ],\n",
       "       [ 0.405 ,  6.565 ],\n",
       "       [ 0.713 ,  6.081 ],\n",
       "       [ 0.52  ,  6.167 ],\n",
       "       [ 0.394 ,  7.454 ],\n",
       "       [ 0.693 ,  6.343 ],\n",
       "       [ 0.489 ,  6.326 ],\n",
       "       [ 0.437 ,  6.279 ],\n",
       "       [ 0.488 ,  6.98  ],\n",
       "       [ 0.871 ,  6.152 ],\n",
       "       [ 0.469 ,  6.421 ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(x_train,y_train)\n",
    "y_predict = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_test = np.sum((y_predict-y_test)**2)/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.810829372693497"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rmse\n",
    "\n",
    "> 与源数据等量级的评价函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.550750343214284"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "rmse_test = sqrt(mse_test)\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0470397434647509"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_test = np.sum(np.absolute(y_test-y_predict))/len(y_test)\n",
    "mae_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MAE/RMSE的局限性在于难以评价同一模型在不同问题中的表现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> R^2 = 1- SS_residual/SS_total\n",
    "\n",
    "SS_residual : Residual Sum of Squares\n",
    "\n",
    "SS_total  :  Total Sum of Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> R^2 = 1- (y_predict-y_true).dot(y_predict-y_true)/(y_mean-y_true).dot(y_mean-y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 分子描述的是使用预测的模型产生的错误，分母是使用Y的均值作为预测值的模型产生的错误(base_line model).R^2表示的是我们的模型对数据的拟合度。类似于另一个lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    "\n",
    "R^2 <= 1  \n",
    "\n",
    "R^2 越大越好，当预测模型不犯错误时，R^2 = 1  \n",
    "\n",
    "当我们的模型等于基准模型时，R^2为0  \n",
    "\n",
    "如果R^2 < 0,说明我们的模型还不如基准模型。此时，很可能我们的数据没有线性关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> R^2 = 1- MSE(y^,y)/Var(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58801207609428385"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多元线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = b + a1*x1 + a2*x2 +......... + an*xn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y^i = a0 + a1 *X1i +a2*X2i+ ...... + an*Xni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求解思路：目标：使(y_predict-y_true).dot(y_predict-y_true) 尽可能的小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标： 找到a0 ..an使目标函数尽可能的小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================================\n",
    "a = (a0 ,a1,.......an)T  \n",
    "\n",
    "y^i = a0*X0i + a1 *X1i +a2*X2i+ ...... + an*Xni    X0i=1  \n",
    "\n",
    "Xi = (X0i,X1i,...........,Xni)  \n",
    "\n",
    "y^i = Xi * A\n",
    "\n",
    "Xb =  [1,  \n",
    "      X1,  \n",
    "      X2,  \n",
    "      X3 ,  \n",
    "      ...  \n",
    "      Xm]  \n",
    "      \n",
    " y^ = Xb*a\n",
    " \n",
    " 目标： 使（Y - Xb\\*a）T(Y-Xb\\*a)尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这时，目标函数求导，得到：\n",
    "a = (XbT\\*Xb)^-1 \\* XbT\\*Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================  \n",
    "\n",
    "这种求解方案的缺点： 时间复杂度高：O(n^3),最优是O(n^2.4)  \n",
    "优点：不需要做归一化处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scikit-learn中的线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "X,y = boston.data,boston.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)\n",
    "lr.fit(X_train,y_train)\n",
    "y_predict = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 13)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.28060398e-01,   3.77955693e-02,   5.86107797e-02,\n",
       "         3.24007007e+00,  -1.62222676e+01,   3.89352244e+00,\n",
       "        -1.27879944e-02,  -1.42326864e+00,   2.34513082e-01,\n",
       "        -8.20261127e-03,  -9.29950535e-01,   1.19151410e-02,\n",
       "        -5.48489997e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72585158182300358"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  KNN 解决回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57483346918109357"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_reg = KNeighborsRegressor()\n",
    "knn_reg.fit(X_train,y_train)\n",
    "knn_reg.score(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    7.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "          metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "          weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'weights': ['uniform'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}, {'weights': ['distance'], 'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'p': [1, 2, 3, 4, 5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [{\n",
    "    \"weights\" : [\"uniform\"],\n",
    "    \"n_neighbors\":[i for i in range(1,11)]\n",
    "},\n",
    "    {\n",
    "        \"weights\":[\"distance\"],\n",
    "        \"n_neighbors\":[i for i in range(1,11)],\n",
    "        \"p\":[i for i in range(1,6)]\n",
    "    }\n",
    "]\n",
    "\n",
    "knn_reg = KNeighborsRegressor()\n",
    "grid_search = GridSearchCV(knn_reg,param_grid,n_jobs=-1,verbose=1)\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的gridsearchCV.best_score__和我们自己定义的score可能不一样，不能比较。但好像可以自己定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性回归对数据是有假设的，就是有线性关系。这也是它的参数学习方法的特点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 正规方程法，时间复杂度高，O（n3^）,数据大的情况下不易实现。可以使用梯度下降法比较好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
